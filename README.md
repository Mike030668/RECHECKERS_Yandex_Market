# RECHECKERS_Yandex_Market

![Alt text](images/startt_img.jpg)

# Краткое описание проекта

Решаемые в рамках соревнования задачи:
    <li> Классификация фото по качеству инфографики и фона
    <li> Удаление инфографики с фото
    <li> Размещение товаров на контекстном фоне

В ноутбуках представлены методы решения поставленных задач
    <li> Построение классификатора, геератора данных и обучение представлено в ноутбуке   ([CNN_ Class_SAM_train](https://github.com/Mike030668/RECHECKERS_Yandex_Market/blob/master/CNN_%20Class_SAM_train.ipynb))
    <li> Оценка классификатора представлено в ноутбуке   ([CNN_ Class_SAM_eval](https://github.com/Mike030668/RECHECKERS_Yandex_Market/blob/master/CNN_%20Class_SAM_eval.ipynb))
    <li> Извлечение текста из картинки, сегментаци и детекция основного объекта, выделение маски и генерация фона по маске представлено  в ноутбуке   ([Clip_Dino_SDX_generations_Demo](https://github.com/Mike030668/RECHECKERS_Yandex_Market/blob/master/Clip_Dino_SDX_generations_Demo.ipynb))


## 1. Классификация фото по качеству инфографики и фона
   <li> «хорошая инфографика» (одна или несколько понятных и информативных характеристик товара в текстовом или визуальном оформлении, изображение качественное, понятно, что за товар) - "good_infographics"
   <li> «плохая инфографика» (когда текст без визуального оформления/сложные термины/непонятные символы/только иностранный язык)  -"bad_infographics"
   <li> не относим ни к плохой/ни к хорошей инфографике - "other_infographics"
   <li> «фото без инфографики с хорошим однотонным фоном» -
"clean_photo_good_background"
   <li> «фото без инфографики с плохим фоном» - "clean_photo_bad_background"
   <li> «фото без инфографики с плохим фоном» - "clean_photo_bad_background"

Для извлечения информации из подаваемой картинки используются:
<li> модель для извлечения полей текстов - EasyOCR
<li> модель для детекции и сегментации Segment Anything Model (SAM)
    
![Alt text](images/class_models.png)

Модель клаасификатора построена по аржетиктуре RESNET, но имеет 3 входа
![Alt text](images/resnet.png)

Модель получает с URL после предобработки в генераторе на 3 входа:
<li> картинку 64х64х3
<li> маску пересечений текстов и масок сегментов 64х64х3
<li> логиты от SAM 128x128x3

Проблемы с которыми столкнулись:
<li> Яндекс предоставил датасет на более чемм милион примерв с разметкой. Обучение на таком датасете в рамках соревнования не возможно. Поэтому обучение модели происходило на слкчайных сбалансированных срезах данных.
<li> в полученных данных имеется много битых ссылок на картинки и приходилось это учитывать в генераторе данных
<li> так как загрузка и предобработка от EasyOCR и SAM), то не получается брать много данных и учить много эпох. Поэтому применяем аугментацию

![Alt text](images/augment.png)

Модель способна глубоко учится, но требует много времени. В целом, предсказания оправданы, так как и сама разметка имеет в семе много неодназначного 

![Alt text](images/predicts.png)

## 2. Удаление инфографики с фото

Тут по сути нужно максимально точно детектировать и сегментировать оснвной товар на фото.
Для решения этой задаче вначале применяется модель **CLIP image to text**. 

[Alt text](images/clip.png)

С помощью которой получается максимально доступное описание товара для извления масок по контексту следующей моделью 

[Alt text](images/from_clip.png)

[Alt text](images/from_clip_1.png)


После получения текстового описания с помощью детектора на осное DINO и SAM происходит извлечение масок с большей вероятностью

[Alt text](images/masks.png)

[Alt text](images/segment_maskings.png)



## 3. Размещение товаров на контекстном фоне

Генерация фона происходит по методу Generation In-painting с применением модели Stable Diffusion 
К маске, которая закрывает все, кромы товара, добавляется текстовое описание относящеся к фону для генерации

[Alt text](images/generate_1.png)

[Alt text](images/generate_2.png)
